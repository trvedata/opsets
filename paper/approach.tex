\section{The OpSets Approach}\label{sec:approach}

The OpSets approach is a simple abstraction for describing the consistency properties of a replicated data system.
We outline the general approach in this section, before describing concrete data structures and specifications in Sections~\ref{sec:datatypes} and~\ref{sec:tree}.

\subsection{System Model}\label{sec:system-model}

We assume that the system consists of a set of \emph{nodes} connected by a network.
These nodes concurrently access some \emph{shared data structure}, which may be a relational database (consisting of rows in tables), a text document (a sequence of characters), a vector-graphics document (a tree of records describing graphical objects), a filesystem (a tree of directories and files), or any other kind of data structure.

We assume that each node has a local copy of the shared data structure, which it can read and modify without distributed locking or any other coordination with other nodes.
Whenever a node makes a modification to that structure, it records the change as an \emph{operation}.
For example, an operation may describe a particular insertion at a particular position in a text document.

We assume that each operation has a unique identifier (ID), and that we have a total ordering on operation IDs.
This total order is a linear extension of the partial order that captures their causal dependencies (the \emph{happens-before} relation).
That is, whenever a node changes the shared data and generates a new operation, the ID of the new operation must be greater than that of any existing operation in the OpSet of the node generating the new operation.
This requirement can easily be met by using Lamport timestamps \cite{Lamport:1978jq} as IDs.

Each node locally maintains a set of operations, the \emph{OpSet}.
Whenever a node makes a change, it adds the corresponding operation to its OpSet, and also sends the operation to other nodes.
Whenever a node receives an operation from another node, that operation is also added to the recipient's local OpSet.
Any operations that are lost in the network are retransmitted as necessary.
Operations remain immutable throughout this process.

Thus, the OpSet at each node is a monotonically growing set of operations, and every operation is eventually contained in the OpSet of every node from which it is not permanently partitioned.
%(To deal with unbounded growth, we discuss garbage collection later in this paper.)
Any two communicating nodes can merge their OpSets using the standard set union operator $\cup$, which is commutative, associative, and idempotent, ensuring that communicating nodes converge towards the same OpSet contents.

\subsection{Interpreting an OpSet}\label{sec:op-serial}

Most definitions of operation-based CRDTs describe how a node's local state is manipulated by operations \cite{Shapiro:2011wy,Shapiro:2011un}.
We now depart from this convention and present an alternative formulation of replicated datatypes.

In the OpSets approach, we require that the shared data structure is never manipulated directly.
Instead, we use an \emph{interpretation function} $\llbracket O \rrbracket$ that takes an OpSet $O$ and returns the current state of the shared data structure described by the OpSet.
The interpretation function is \emph{pure}, i.e.\ deterministic, side-effect free, and its result depends only on $O$.
All nodes in the system employ the same interpretation function.

Consequently, whenever any two nodes have the same OpSet $O$, their view of the shared data structure $\llbracket O \rrbracket$ must also be equal.
This construction trivially ensures eventual consistency: as two nodes converge towards the same OpSet contents, any data structure that is deterministically derived from the OpSet must also converge.

In principle, any deterministic function can serve as interpretation function $\llbracket O \rrbracket$ of the OpSet $O$.
However, in defining the semantics of CRDTs (see Sections~\ref{sec:datatypes} and~\ref{sec:tree}), we have found it useful to specialise $\llbracket O \rrbracket$ such that we can interpret one operation at a time.

Let the OpSet $O$ be a set of pairs $(\mathit{id},\, \mathit{op})$, where $\mathit{id}$ is a unique operation identifier and $\mathit{op}$ is an arbitrary description of the change that occurred.
Assume that we have a total ordering $<$ on identifiers, as explained in Section~\ref{sec:system-model}.
Then observe that for any OpSet there exists a unique sequence of operations, containing all operations of the OpSet in ascending order of their identifier.
We can specify the semantics of each operation~--- that is, the effect of the operation on the query result~--- when applied in this sequential order.

Formally, we can define the interpretation $\llbracket O \rrbracket$ of the OpSet $O$ as follows:
\begin{align*}
    \big\llbracket \emptyset \big\rrbracket &= \mathit{InitialState} \\
    \big\llbracket O \;\cup\; \{(\mathit{id},\, \mathit{op})\} \big\rrbracket &=
    \mathrm{interp}\big[\llbracket O \rrbracket,\, (\mathit{id},\, \mathit{op})\big]
    \qquad\text{ provided that } \forall\,(\mathit{id}',\, \mathit{op}') \in O.\; \mathit{id}' < \mathit{id}
\end{align*}
where $\mathrm{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is the interpretation of the operation $(\mathit{id},\, \mathit{op})$ in the state $S$.
In other words, if $S$ is the result of interpreting all operations with identifiers less than $\mathit{id}$, then
$\mathrm{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is the interpretation of the OpSet to which $(\mathit{id},\, \mathit{op})$ has been added.
For example, if $\mathit{id}_1 < \mathit{id}_2 < \mathit{id}_3$, we have:
\[ \big\llbracket \{(\mathit{id}_1,\ \mathit{op}_1),\,
    (\mathit{id}_2,\ \mathit{op}_2),\,
    (\mathit{id}_3,\ \mathit{op}_3)\} \big\rrbracket \;=\;
    \mathrm{interp}\big[\mathrm{interp}\big[\mathrm{interp}\big[\mathit{InitialState},\,
    (\mathit{id}_1,\ \mathit{op}_1)\big],\,
    (\mathit{id}_2,\ \mathit{op}_2)\big],\,
    (\mathit{id}_3,\ \mathit{op}_3)\big] \]
Provided that the operation interpretation $\mathrm{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is deterministic, the OpSet interpretation function $\llbracket-\rrbracket$ is also deterministic, due to the fact that the operation order in the OpSet is unique.

In real systems it is likely that operations arrive at nodes in an order that does not match their $\mathit{id}$ order.
If a new operation $(\mathit{id},\, \mathit{op})$ is added to a node's OpSet $O$, and $\exists\,(\mathit{id}',\, \mathit{op}') \in O.\; \mathit{id}' > \mathit{id}$,
then $\mathrm{interp}\big[\llbracket O \rrbracket,\, (\mathit{id},\, \mathit{op})\big]$ cannot be used directly to compute the updated OpSet interpretation
$\big\llbracket O \;\cup\; \{(\mathit{id},\, \mathit{op})\} \big\rrbracket$.
Instead, the node would have to first compute the interpretation of all operations with lower IDs,
$\big\llbracket \{(\mathit{id}',\, \mathit{op}') \in O \mid \mathit{id}' < \mathit{id}\} \big\rrbracket$,
then apply the new operation $(\mathit{id},\, \mathit{op})$, and finally re-apply all operations with greater IDs.

Our interpretation functions can be seen as \emph{executable specifications} that define the expected result of interpreting a set of operations.
We argue that presenting replicated datatypes in this manner has two significant advantages:
\begin{enumerate}
\item
Unlike typical definitions of CRDT algorithms \cite{Shapiro:2011wy,Shapiro:2011un}, it is not necessary for the interpretation function $\mathrm{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ to commute with respect to other operations: any pure function can be used.
This fact makes it much simpler to specify the interpretation of operations, as we shall see in Sections~\ref{sec:datatypes} and~\ref{sec:tree}.
\item
We can guarantee the existence of an implementation of each described datatype: the specification itself.
This is in contrast to axiomatic specifications, which may not be implementable, and require additional work to demonstrate than an implementation exists which satisfies the axiomatic description.
\end{enumerate}

For an \emph{implementation}, each node retaining an explicit OpSet may induce poor performance, depending on the use-case and application, since nodes must potentially apply the same subset of operations repeatedly.
More efficient (and, most likely, more complex) algorithms for CRDTs can therefore be developed and shown to satisfy the OpSet-based specification---we do this in Section~\ref{sec:datatypes}.
However, building an implementation around OpSets does have some advantages: for example, using OpSets provides a straightforward mechanism for recovering from network partitions and failures, as missing operations may be retransmitted and added to the OpSets of previously partitioned nodes.
Similarly, new nodes joining a network can also be initialised with the union of OpSets of existing nodes.
