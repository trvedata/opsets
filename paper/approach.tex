\section{The OpSets Approach}\label{sec:approach}

The OpSets approach is a simple abstraction for describing the consistency properties of a replicated data system.
We outline the general approach in this section, before describing concrete data structures and specifications in \S~\ref{sec:datatypes} and \S~\ref{sec:tree}.

\subsection{System Model}\label{sec:system-model}

We assume that the system consists of a set of \emph{nodes} connected by a \emph{network}.
These nodes concurrently access some \emph{shared data structure}, which may be a relational database (consisting of rows in tables), a text document (a sequence of characters), a vector-graphics document (a tree of records describing graphical objects), a filesystem (a tree of directories and files), or any other kind of data structure.

New nodes can be added at any time, and the set of nodes need not be known in advance.
Nodes might be mobile devices, and hence we assume that nodes are sometimes \emph{offline}, i.e.\ temporarily unable to communicate with other nodes.
We require that nodes can access the shared data anytime, even while offline.
Thus, each node has a local copy of the shared data structure, which it can read and modify without waiting for any communication or coordination with other nodes.

Whenever a node makes a modification to that structure, it records the change as an \emph{operation}.
For example, an operation may describe an insertion at a particular position in a text document.
Each node locally maintains a set of operations, the \emph{OpSet}.
Whenever a node makes a change to the shared data, it adds the corresponding operation to its OpSet, and also sends \emph{messages} containing the operation to other nodes.
Whenever a node receives a message from another node, the operation in that message is added to the recipient's local OpSet.
Operations remain immutable throughout this process.

We make no assumptions about the reliability of the network: messages may be lost, duplicated, or arbitrarily reordered.
Reflecting the characteristics of real networks, we assume that lost messages are retransmitted when possible (e.g.\ using TCP), but messages may be permanently lost due to network or node failures.
Since the OpSet at each node is a monotonically growing set of operations, any two communicating nodes can merge their OpSets using the standard set union operator $\cup$.
Set union is commutative, associative, and idempotent, ensuring that communicating nodes converge towards the same OpSet contents.

We assume that each operation has a unique identifier (ID), that new IDs can be generated by any node without communication with other nodes, and that we have a total ordering on operation IDs.
These requirements can easily be met by using Lamport timestamps \cite{Lamport:1978jq} as IDs.
A Lamport timestamp is a pair $(\mathit{counter}, \mathit{nodeID})$ that is constructed as follows:
\begin{itemize}
\item $\mathit{counter}$ is an integer.
    To generate a new ID, find the maximum counter of any existing operation ID in the local OpSet, and increment that number.
\item $\mathit{nodeID}$ is a string that uniquely identifies the node generating the ID, e.g.\ a UUID \cite{Leach:2005hm}.
\end{itemize}

Although different nodes may generate IDs with the same counter value, each node generates IDs with strictly increasing counter values, and thus IDs are globally unique.
We define the total order on IDs as being the lexicographic order:
\[
    \,(\mathit{ctr}_1, \mathit{node}_1) < (\mathit{ctr}_2, \mathit{node}_2)\,
    \;\Longleftrightarrow\;
    \mathit{ctr}_1 < \mathit{ctr}_2 \;\vee\;
    (\mathit{ctr}_1 = \mathit{ctr}_2 \wedge \mathit{node}_1 <\mathit{node}_2).
\]

%This total order is a linear extension of the partial order that captures their causal dependencies (the \emph{happens-before} relation).
%That is, whenever a node changes the shared data and generates a new operation, the ID of the new operation must be strictly greater than that of any existing operation in the OpSet of the node generating the new operation.

\subsection{Interpreting an OpSet}\label{sec:op-serial}

Most definitions of operation-based CRDTs describe how a node's local state is manipulated by operations \cite{Shapiro:2011wy,Shapiro:2011un}.
We now depart from this convention and present an alternative formulation of replicated datatypes.

In the OpSets approach, we require that the shared data structure is never manipulated directly.
Instead, we use an \emph{interpretation function} $\llbracket-\rrbracket$ that takes an OpSet $O$ and returns the current state $\llbracket O \rrbracket$ of the shared data structure described by the OpSet.
The interpretation function is \emph{pure}, i.e.\ deterministic, side-effect free, and its result depends only on $O$.
All nodes in the system employ the same interpretation function.

Consequently, whenever any two nodes have the same OpSet $O$, their view of the shared data structure $\llbracket O \rrbracket$ must also be equal.
This construction trivially ensures eventual consistency: as two nodes converge towards the same OpSet contents, any data structure that is deterministically derived from the OpSet must also converge.

In principle, any deterministic function can serve as interpretation function.
However, in defining the semantics of CRDTs (see \S~\ref{sec:datatypes} and \S~\ref{sec:tree}), we have found it useful to specialise $\llbracket-\rrbracket$ such that we can interpret one operation at a time.

Let the OpSet $O$ be a set of pairs $(\mathit{id},\, \mathit{op})$, where $\mathit{id}$ is a unique operation identifier and $\mathit{op}$ is an arbitrary description of the change that occurred.
Assume that we have a total ordering $<$ on identifiers, as explained in \S~\ref{sec:system-model}.
Then observe that for any OpSet there exists a unique sequence of operations, containing all operations of the OpSet in ascending order of their identifier.
We can specify the semantics of each operation~--- that is, the effect of the operation on the OpSet interpretation~--- when applied in this sequential order.

Formally, we can define the interpretation $\llbracket O \rrbracket$ of the OpSet $O$ as follows:
\begin{align*}
    \big\llbracket \emptyset \big\rrbracket &= \mathsf{InitialState} \\
    \big\llbracket O \;\cup\; \{(\mathit{id},\, \mathit{op})\} \big\rrbracket &=
    \mathsf{interp}\big[\llbracket O \rrbracket,\, (\mathit{id},\, \mathit{op})\big]
    \qquad\text{ provided that } \forall\,(\mathit{id}',\, \mathit{op}') \in O.\; \mathit{id}' < \mathit{id}
\end{align*}
where $\mathsf{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is the interpretation of the operation $(\mathit{id},\, \mathit{op})$ in the state $S$, and $\mathsf{InitialState}$ is a fixed minimal element (e.g. the empty tree, or empty list) of the replicated type described.
In other words, if $S$ is the result of interpreting all operations with identifiers less than $\mathit{id}$, then
$\mathsf{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is the interpretation of the OpSet to which $(\mathit{id},\, \mathit{op})$ has been added.
For example, if $\mathit{id}_1 < \mathit{id}_2 < \mathit{id}_3$, we have:
\begin{align*}
    \big\llbracket \{(\mathit{id}_1,\ \mathit{op}_1),\;
    &(\mathit{id}_2,\ \mathit{op}_2),\,
    (\mathit{id}_3,\ \mathit{op}_3)\} \big\rrbracket \;=\\
    &\mathsf{interp}\big[\mathsf{interp}\big[\mathsf{interp}\big[\mathsf{InitialState},\,
    (\mathit{id}_1,\ \mathit{op}_1)\big],\,
    (\mathit{id}_2,\ \mathit{op}_2)\big],\,
    (\mathit{id}_3,\ \mathit{op}_3)\big]
\end{align*}
Provided that the operation interpretation $\mathsf{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ is deterministic, the OpSet interpretation function $\llbracket-\rrbracket$ is also deterministic, due to the fact that the operation order in the OpSet is unique.

\subsection{Receiving Messages Out-of-order}\label{sec:order-change}

Many computing systems are based on the idea of putting operations in some total order, and executing them in that order.
For example, serializable transactions \cite{Kleppmann:2017wj} and state machine replication \cite{Schneider:1990vy} follow this approach.
However, it is important to understand that the OpSet interpretation of \S~\ref{sec:op-serial} relies on a weaker notion of ordering than most systems.

With serializable transactions and state machine replication, once a transaction/operation has been executed in some state, its results are expected to be durable.
Thus, before executing some transaction $T_i$, the system needs to ensure that there is no pending transaction with a lower ID than $T_i$ (which would need to be executed before $T_i$), since otherwise the subsequent arrival of a transaction with lower ID would invalidate the state in which $T_i$ was executed.
However, ensuring this precondition is expensive: as we show in \S~\ref{sec:op-sequences}, it requires communication with at least a quorum of nodes; if the IDs are Lamport timestamps, it even requires communication with every single node \cite{Lamport:1978jq}.
If too many nodes are offline, the system cannot execute any transactions.

By contrast, our system model of \S~\ref{sec:system-model} requires nodes to always be able to read and modify the shared data, even when all nodes are offline.
Moreover, we do not assume any ordering guarantees from the network.
Thus, whenever there is some operation $(\mathit{id}_1, \mathit{op}_1) \in O$ in the OpSet $O$ of some node, it is possible that the node will subsequently receive a message containing $(\mathit{id}_2, \mathit{op}_2)$, where $\mathit{id}_2 < \mathit{id}_1$; that is, the later-arriving operation needs to be applied before the existing operation $(\mathit{id}_1, \mathit{op}_1)$ in the OpSet interpretation $\llbracket O \rrbracket$.

In the OpSet model, such out-of-order delivery of operations is no problem: the order in which operations are received has no effect on the OpSet $O$, and since we assume the interpretation function to be pure and side-effect free, the interpretation $\llbracket O \rrbracket$ can always be recomputed whenever new operations are added to $O$.

The interpretation function is an \emph{executable specification} that defines the expected result of interpreting a set of operations.
Presenting replicated datatypes in this manner has two significant advantages:
\begin{enumerate*}
\item
Unlike typical definitions of CRDT algorithms \cite{Shapiro:2011wy,Shapiro:2011un}, it is not necessary for the interpretation function $\mathsf{interp}\big[S,\, (\mathit{id},\, \mathit{op})\big]$ to commute with respect to other operations: any pure function can be used.
This fact makes it much simpler to specify the interpretation of operations, as we shall see in \S~\ref{sec:datatypes} and \S~\ref{sec:tree}.
\item
We can guarantee the existence of an implementation of each described datatype: the specification itself.
This is in contrast to axiomatic specifications, which may not be implementable, and require additional work to demonstrate than an implementation exists which satisfies the axiomatic description.
\end{enumerate*}

For practical implementations of replicated datatypes, a naive OpSet interpretation may exhibit poor performance, since nodes must potentially apply the same subset of operations repeatedly.
More efficient (and, most likely, more complex) algorithms for CRDTs can therefore be developed and shown to satisfy the OpSet-based specification---we do this in \S~\ref{sec:bad-merge}.

However, we have developed a practical JavaScript CRDT implementation around the OpSet model,\footnote{\url{https://github.com/automerge/automerge}} and found it to have some advantages: for example, users can easily inspect the editing history of a document, since every past version of the document is the interpretation of a particular subset of operations.
Moreover, using OpSets provides a straightforward mechanism for recovering from network partitions and failures, as missing operations may be retransmitted and added to the OpSets of previously partitioned nodes.
The details of this implementation are beyond the scope of this paper.
